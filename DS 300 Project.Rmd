---
title: "DS 300 Project"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
data = read.csv('C:/Users/kyle.persin/Desktop/DS 300/student-mat.csv')
```

#ELIMINATE UNNECESSARY VARIABLES

#CREATE A BINARY CLASSIFICAION VARIABLE 

```{r}
data$G4 = ifelse(data$G3 > 10, 
                 yes = 0, 
                 no = 1)
data$G4 = factor(data$G4)
```

#ELIMINATE UNNECESSARY VARIABLES

```{r}
data = subset(data, select = -c(school, reason, traveltime, G1, G2, G3))
```

#SPLIT THE DATA AND TRAIN CLASSIFIERS

```{r}
library(caTools)
set.seed(123)
split = sample.split(data$G4, SplitRatio = 0.75)
training_set = subset(data, split == TRUE)
test_set = subset(data, split == FALSE)

```


# Log Reg:
```{r}
logreg_class = glm(formula = G4 ~ .,
                   family = binomial, 
                   data = training_set)

logreg_probs = predict(logreg_class, 
                       type = 'response', 
                       newdata = test_set[,-28])
```

```{r}
accuracy_logreg = ifelse(test = logreg_probs > .5, 
                         yes = 1, 
                         no = 0)
accuracy_logreg = factor(accuracy_logreg)
```

#decision tree
```{r}
library(rpart)
dt_class = rpart(formula = G4 ~ .,
                 data = training_set)

dt_preds = predict(dt_class, newdata = test_set[,-28], type = 'prob')
dt_probs = dt_preds[, 2]
```

```{r}
accuracy_dt = ifelse(test = dt_probs > .5, 
                         yes = 1, 
                         no = 0)
accuracy_dt = factor(accuracy_dt)
```

#random forest
```{r}
library(randomForest)

rf_class = randomForest(x = training_set[,-28],
                        y = training_set$G4,
                        ntree = 100)
rf_preds = predict(rf_class, 
                   newdata = test_set[,-28], 
                   type = 'prob')
rf_probs = rf_preds[, 2]
```

```{r}
accuracy_rf = ifelse(test = rf_probs > .5, 
                         yes = 1, 
                         no = 0)
accuracy_rf = factor(accuracy_rf)
```

#CHECK ACCURACY

```{r}
library(caret)
confusionMatrix(test_set$G4, accuracy_dt)
confusionMatrix(test_set$G4, accuracy_logreg)
confusionMatrix(test_set$G4, accuracy_rf)
```

#CREATING ROC CURVES

```{r}
library(pROC)

logregROC = roc(test_set$G4 ~ logreg_probs, plot=TRUE, print.auc=TRUE, col="red", lwd =2, legacy.axes=TRUE, main="ROC Curves")

rfROC = roc(test_set$G4 ~ rf_probs, plot=TRUE, print.auc=TRUE, col="blue", lwd =2, legacy.axes=TRUE, main="ROC Curves")


dtROC = roc(test_set$G4 ~ dt_probs, plot=TRUE, print.auc=TRUE, col="black", lwd = 2, print.auc.y=0.4, legacy.axes=TRUE, add = TRUE)

legend("bottomright",legend=c("Logistic Regression","Random Forest", "Decisioin Tree"), col=c("red", "blue", "black"), lwd=4, cex = 0.5)
```

#CHECKING AUC

```{r}
auc(dtROC)
auc(rfROC)
auc(logregROC)
```



